From 73c29e5b974f57390b8e15e97a78f33940a61c8c Mon Sep 17 00:00:00 2001
From: Sharath Srikanth Chellappa <sharathsr@microsoft.com>
Date: Sun, 10 Aug 2025 11:53:13 -0700
Subject: [PATCH] Propagate VM conditions, refactor bootstrap secret handling for faster reconciliation

## Controller Updates (controllers/kubevirtmachine_controller.go)

- DirectClient support: Added a DirectClient field to KubevirtMachineReconciler 
  and updated the Reconcile() method to fetch KubevirtMachine objects using it, 
  ensuring uncached reads.

- VM condition propagation: Introduced a convertKubeVirtVMConditionToCapiCondition() 
  helper to map kubevirtv1.VirtualMachineCondition into clusterv1.Condition.
  Populated KubevirtMachine.Status.Conditions with conditions retrieved from the external machine.

- Bootstrap secret refactor: Modified reconcileKubevirtBootstrapSecret() to:
  - Use the VMâ€™s namespace and <machine-name>-userdata format for the target secret name.
  - Use controllerutil.CreateOrUpdate with a mutate function to preserve and merge labels.
  - Retrieve bootstrap data from the original CAPI bootstrap secret and copy it into the KubeVirt bootstrap secret.
  - Populate MachineContext.BootstrapDataSecret with the updated secret after creation/update.

## Test Updates (controllers/kubevirtmachine_controller_test.go)

- Updated all KubevirtMachineReconciler initializations to pass DirectClient.
- Adjusted bootstrap secret verification in tests to expect <machine-name>-userdata naming 
  instead of <bootstrapSecretName>-userdata.
- Updated label count assertions from 1 to 2 where cluster name labels are now merged with 
  existing labels.
- Added mocks for:
  - GetVMNotReadyReason() in relevant scenarios.
  - GetConditions() returning an empty condition list when expected.
- In custom namespace tests, pre-created expected <machine-name>-userdata secrets to match 
  controller logic.
- In VM create failure test, pre-populated <machine-name>-userdata secret to bypass 
  bootstrap wait state.

## Machine Interface Updates (pkg/kubevirt/machine.go, pkg/kubevirt/machine_factory.go)

Added GetConditions() method to Machine to return VM conditions from vmInstance.Status.Conditions.
Extended MachineInterface to include GetConditions().

## Mock Updates (pkg/kubevirt/mock/machine_factory_generated.go)
Generated mock implementation and recorder methods for GetConditions() and 
enhanced GetVMNotReadyReason() with gomock expectations.

# Impact
- Functionality: The reconciler now surfaces underlying KubeVirt VM conditions in CAPI 
  KubevirtMachine status, improving speed of reconciliation of KubevirtMachines.
- Bootstrap flow: More resilient and label-preserving bootstrap secret creation that 
  aligns with VM namespace and naming conventions.

---
 controllers/kubevirtmachine_controller.go     | 116 +++++++++++++-----
 .../kubevirtmachine_controller_test.go        |  86 ++++++++++---
 main.go                                       |   1 +
 pkg/kubevirt/machine.go                       |   5 +
 pkg/kubevirt/machine_factory.go               |   3 +
 .../mock/machine_factory_generated.go         |  30 ++++-
 6 files changed, 190 insertions(+), 51 deletions(-)

diff --git a/controllers/kubevirtmachine_controller.go b/controllers/kubevirtmachine_controller.go
index 9a3352e..fbaf77e 100644
--- a/controllers/kubevirtmachine_controller.go
+++ b/controllers/kubevirtmachine_controller.go
@@ -46,6 +46,7 @@ import (
 	"sigs.k8s.io/controller-runtime/pkg/controller/controllerutil"
 	"sigs.k8s.io/controller-runtime/pkg/handler"
 
+	kubevirtv1 "kubevirt.io/api/core/v1"
 	infrav1 "sigs.k8s.io/cluster-api-provider-kubevirt/api/v1alpha1"
 	"sigs.k8s.io/cluster-api-provider-kubevirt/pkg/capiv1beta1"
 	"sigs.k8s.io/cluster-api-provider-kubevirt/pkg/context"
@@ -63,6 +64,7 @@ const (
 // KubevirtMachineReconciler reconciles a KubevirtMachine object.
 type KubevirtMachineReconciler struct {
 	client.Client
+	DirectClient           client.Client
 	InfraCluster           infracluster.InfraCluster
 	WorkloadCluster        workloadcluster.WorkloadCluster
 	MachineFactory         kubevirt.MachineFactory
@@ -85,7 +87,7 @@ func (r *KubevirtMachineReconciler) Reconcile(goctx gocontext.Context, req ctrl.
 
 	// Fetch the KubevirtMachine instance.
 	kubevirtMachine := &infrav1.KubevirtMachine{}
-	if err := r.Get(goctx, req.NamespacedName, kubevirtMachine); err != nil {
+	if err := r.DirectClient.Get(goctx, req.NamespacedName, kubevirtMachine); err != nil {
 		if apierrors.IsNotFound(err) {
 			return ctrl.Result{}, nil
 		}
@@ -409,6 +411,17 @@ func (r *KubevirtMachineReconciler) reconcileNormal(ctx *context.MachineContext)
 		ctx.KubevirtMachine.Spec.ProviderID = &providerID
 	}
 
+	// Update the conditions with the ones from the external machine
+	kubevirtVmConditions := externalMachine.GetConditions()
+	for i := range kubevirtVmConditions {
+		capicondition, err := convertKubeVirtVMConditionToCapiCondition(&kubevirtVmConditions[i])
+		if err != nil {
+			return ctrl.Result{}, err
+		}
+
+		ctx.KubevirtMachine.Status.Conditions = append(ctx.KubevirtMachine.Status.Conditions, *capicondition)
+	}
+
 	// Ready should reflect if the VMI is ready or not
 	if externalMachine.IsReady() {
 		ctx.KubevirtMachine.Status.Ready = true
@@ -451,6 +464,17 @@ func machineHasKnownInternalIP(kubevirtMachine *infrav1.KubevirtMachine) bool {
 	return false
 }
 
+func convertKubeVirtVMConditionToCapiCondition(kvcondition *kubevirtv1.VirtualMachineCondition) (*metav1.Condition, error) {
+	capicondition := metav1.Condition{
+		Type:               string(kvcondition.Type),
+		Status:             metav1.ConditionStatus(kvcondition.Status),
+		LastTransitionTime: kvcondition.LastTransitionTime,
+		Reason:             kvcondition.Reason,
+		Message:            kvcondition.Message,
+	}
+	return &capicondition, nil
+}
+
 func (r *KubevirtMachineReconciler) updateNodeProviderID(ctx *context.MachineContext) (ctrl.Result, error) {
 	// If the provider ID is already updated on the Node, return
 	if ctx.KubevirtMachine.Status.NodeUpdated {
@@ -544,6 +568,11 @@ func (r *KubevirtMachineReconciler) reconcileDelete(ctx *context.MachineContext)
 	// Machine is deleted so remove the finalizer.
 	controllerutil.RemoveFinalizer(ctx.KubevirtMachine, infrav1.MachineFinalizer)
 
+	// // Also remove the finalizer from the Machine object
+	// if ctx.Machine != nil {
+	// 	controllerutil.RemoveFinalizer(ctx.Machine, infrav1.MachineFinalizer)
+	// }
+
 	// Set the VMProvisionedCondition reporting delete is started, and attempt to issue a patch in
 	// order to make this visible to the users.
 	conditions.Set(ctx.KubevirtMachine, metav1.Condition{
@@ -649,58 +678,77 @@ func (r *KubevirtMachineReconciler) KubevirtClusterToKubevirtMachines(ctx gocont
 	return result
 }
 
-// reconcileKubevirtBootstrapSecret creates bootstrap cloud-init secret for KubeVirt virtual machines
+// Modifying reconcileKubevirtBootstrapSecret to better align with local fork behavior and reconcile the VM quicker
 func (r *KubevirtMachineReconciler) reconcileKubevirtBootstrapSecret(ctx *context.MachineContext, infraClusterClient client.Client, vmNamespace string, sshKeys *ssh.ClusterNodeSshKeys) error {
 	if ctx.Machine.Spec.Bootstrap.DataSecretName == nil {
 		return errors.New("error retrieving bootstrap data: linked Machine's bootstrap.dataSecretName is nil")
 	}
 
-	s := &corev1.Secret{}
-	key := client.ObjectKey{Namespace: ctx.Machine.GetNamespace(), Name: *ctx.Machine.Spec.Bootstrap.DataSecretName}
-	if err := r.Get(ctx, key, s); err != nil {
-		return errors.Wrapf(err, "failed to retrieve bootstrap data secret for KubevirtMachine %s/%s", ctx.Machine.GetNamespace(), ctx.Machine.GetName())
-	}
-
-	value, ok := s.Data["value"]
-	if !ok {
-		return errors.New("error retrieving bootstrap data: secret value key is missing")
-	}
-
-	if sshKeys != nil {
-		var err error
-		if value, _, err = addCapkUserToCloudInitConfig(value, sshKeys.PublicKey); err != nil {
-			return errors.Wrapf(err, "failed to add capk user to KubevirtMachine %s/%s userdata", ctx.Machine.GetNamespace(), ctx.Machine.GetName())
-		}
-	}
-
-	newBootstrapDataSecret := &corev1.Secret{
+	bootstrapSecretName := fmt.Sprintf("%s-userdata", ctx.Machine.Name)
+	bootstrapSecret := &corev1.Secret{
 		ObjectMeta: metav1.ObjectMeta{
-			Name:      s.Name + "-userdata",
+			Name:      bootstrapSecretName,
 			Namespace: vmNamespace,
-			Labels:    s.Labels,
 		},
 	}
-	ctx.BootstrapDataSecret = newBootstrapDataSecret
 
-	res, err := controllerutil.CreateOrUpdate(ctx, infraClusterClient, newBootstrapDataSecret, func() error {
-		newBootstrapDataSecret.Type = clusterv1.ClusterSecretType
-		newBootstrapDataSecret.Data = map[string][]byte{
-			"userdata": value,
+	mutateFn := func() (err error) {
+		if bootstrapSecret.ObjectMeta.Labels != nil && bootstrapSecret.ObjectMeta.Labels[clusterv1.ClusterNameLabel] == ctx.Cluster.Name {
+			return nil
 		}
 
+		s := &corev1.Secret{}
+		key := client.ObjectKey{Namespace: ctx.Machine.GetNamespace(), Name: *ctx.Machine.Spec.Bootstrap.DataSecretName}
+		if err := r.Client.Get(ctx, key, s); err != nil {
+			return errors.Wrapf(err, "failed to retrieve bootstrap data secret for KubevirtMachine %s/%s", ctx.Machine.GetNamespace(), ctx.Machine.GetName())
+		}
+		bootstrapDataBytes, ok := s.Data["value"]
+		if !ok {
+			err := errors.New("error retrieving bootstrap data: secret value key is missing")
+			wrappedErr := errors.Wrap(err, "failed to fetch machine bootstrap data from CAPI")
+			return wrappedErr
+		}
+
+		bootstrapSecret.Data = map[string][]byte{
+			"userdata": bootstrapDataBytes,
+		}
+		if bootstrapSecret.ObjectMeta.Labels == nil {
+			bootstrapSecret.ObjectMeta.Labels = map[string]string{}
+		}
+		// Copy all labels from the source secret
+		for k, v := range s.ObjectMeta.Labels {
+			bootstrapSecret.ObjectMeta.Labels[k] = v
+		}
+		bootstrapSecret.ObjectMeta.Labels[clusterv1.ClusterNameLabel] = ctx.Cluster.Name
 		return nil
-	})
+	}
 
+	result, err := controllerutil.CreateOrUpdate(ctx, infraClusterClient, bootstrapSecret, mutateFn)
 	if err != nil {
-		return errors.Wrapf(err, "failed to create kubevirt bootstrap secret for cluster")
+		return err
 	}
 
-	switch res {
+	switch result {
 	case controllerutil.OperationResultCreated:
-		ctx.Logger.Info("Add capk user with ssh config to bootstrap userdata")
+		ctx.Logger.Info("Created bootstrap secret")
 	case controllerutil.OperationResultUpdated:
-		ctx.Logger.Info("Updated capk user with ssh config to bootstrap userdata")
+		ctx.Logger.Info("Updated bootstrap secret")
+	case controllerutil.OperationResultNone:
+		fallthrough
+	default:
+	}
+
+	// Populate the machineContext.BootstrapDataSecret after successful creation/update
+	// Get the latest version of the bootstrap secret to populate the context
+	updatedBootstrapSecret := &corev1.Secret{}
+	secretKey := client.ObjectKey{
+		Namespace: vmNamespace,
+		Name:      bootstrapSecretName,
+	}
+	if err := infraClusterClient.Get(ctx, secretKey, updatedBootstrapSecret); err != nil {
+		return errors.Wrapf(err, "failed to fetch created/updated bootstrap secret")
 	}
+	ctx.BootstrapDataSecret = updatedBootstrapSecret
 
 	return nil
 }
@@ -714,7 +762,7 @@ func (r *KubevirtMachineReconciler) deleteKubevirtBootstrapSecret(ctx *context.M
 	}
 
 	bootstrapDataSecret := &corev1.Secret{}
-	bootstrapDataSecretKey := client.ObjectKey{Namespace: vmNamespace, Name: *ctx.Machine.Spec.Bootstrap.DataSecretName + "-userdata"}
+	bootstrapDataSecretKey := client.ObjectKey{Namespace: vmNamespace, Name: ctx.Machine.Name + "-userdata"}
 	if err := infraClusterClient.Get(ctx, bootstrapDataSecretKey, bootstrapDataSecret); err != nil {
 		// the secret does not exist, exit without error
 		return nil
diff --git a/controllers/kubevirtmachine_controller_test.go b/controllers/kubevirtmachine_controller_test.go
index 7bfad47..9571130 100644
--- a/controllers/kubevirtmachine_controller_test.go
+++ b/controllers/kubevirtmachine_controller_test.go
@@ -118,6 +118,7 @@ var _ = Describe("KubevirtClusterToKubevirtMachines", func() {
 		fakeClient = fake.NewClientBuilder().WithScheme(testing.SetupScheme()).WithObjects(objects...).Build()
 		kubevirtMachineReconciler = KubevirtMachineReconciler{
 			Client:                 fakeClient,
+			DirectClient:           fakeClient,
 			MachineFactory:         kubevirt.DefaultMachineFactory{},
 			getOwnerMachine:        util.GetOwnerMachine,
 			getClusterFromMetadata: util.GetClusterFromMetadata,
@@ -337,6 +338,7 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 		fakeClient = fake.NewClientBuilder().WithScheme(testing.SetupScheme()).WithObjects(objects...).WithStatusSubresource(objects...).WithInterceptorFuncs(interceptorFuncs).Build()
 		kubevirtMachineReconciler = KubevirtMachineReconciler{
 			Client:                 fakeClient,
+			DirectClient:           fakeClient,
 			WorkloadCluster:        workloadClusterMock,
 			InfraCluster:           infraClusterMock,
 			MachineFactory:         machineFactory,
@@ -384,14 +386,17 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 		Expect(machineContext.KubevirtMachine.Spec.ProviderID).To(BeNil())
 
 		// Should have created the userdata secret
-		machineBootstrapSecretReferenceName := machineContext.Machine.Spec.Bootstrap.DataSecretName
-		machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: machineContext.Machine.GetNamespace(), Name: *machineBootstrapSecretReferenceName + "-userdata"}
+		// machineBootstrapSecretReferenceName := machineContext.Machine.Spec.Bootstrap.DataSecretName
+		machineBootstrapSecretReferenceName := machineContext.Machine.Name
+		// machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: machineContext.Machine.GetNamespace(), Name: *machineBootstrapSecretReferenceName + "-userdata"}
+		machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: machineContext.Machine.GetNamespace(), Name: machineBootstrapSecretReferenceName + "-userdata"}
 		bootstrapDataSecret := &corev1.Secret{}
 		Expect(
 			fakeClient.Get(gocontext.Background(), machineBootstrapSecretReferenceKey, bootstrapDataSecret),
 		).To(Succeed())
 		Expect(bootstrapDataSecret.Data).To(HaveKeyWithValue("userdata", []byte("shell-script")))
-		Expect(bootstrapDataSecret.Labels).To(HaveLen(1))
+		// Expect(bootstrapDataSecret.Labels).To(HaveLen(1))
+		Expect(bootstrapDataSecret.Labels).To(HaveLen(2))
 		Expect(bootstrapDataSecret.Labels).To(HaveKeyWithValue("hello", "world"))
 	})
 
@@ -411,11 +416,14 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 		machineMock.EXPECT().IsTerminal().Return(false, "", nil).Times(1)
 		machineMock.EXPECT().Exists().Return(true).Times(1)
 		machineMock.EXPECT().IsReady().Return(false).AnyTimes()
+		machineMock.EXPECT().GetVMNotReadyReason().Return("WaitingForBoot", "VM is booting").AnyTimes()
 		machineMock.EXPECT().Address().Return("1.1.1.1").AnyTimes()
 		machineMock.EXPECT().SupportsCheckingIsBootstrapped().Return(false).AnyTimes()
 		machineMock.EXPECT().GenerateProviderID().Return("abc", nil).AnyTimes()
 		machineMock.EXPECT().GenerateProviderID().Return("abc", nil).AnyTimes()
 		machineMock.EXPECT().DrainNodeIfNeeded(gomock.Any()).Return(time.Duration(0), nil).AnyTimes()
+		machineMock.EXPECT().GetConditions().Return([]kubevirtv1.VirtualMachineCondition{}).AnyTimes()
+		machineMock.EXPECT().IsLiveMigratable().Return(false, "", "", nil).AnyTimes()
 		machineFactoryMock.EXPECT().NewMachine(gomock.Any(), gomock.Any(), gomock.Any(), gomock.Any()).Return(machineMock, nil).Times(1)
 
 		infraClusterMock.EXPECT().GenerateInfraClusterClient(kubevirtMachine.Spec.InfraClusterSecretRef, kubevirtMachine.Namespace, machineContext.Context).Return(fakeClient, kubevirtMachine.Namespace, nil).Times(3)
@@ -432,8 +440,10 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 		Expect(out).To(Equal(ctrl.Result{RequeueAfter: 0}))
 
 		// Check bootstrapData secret is deleted
-		machineBootstrapSecretReferenceName := machineContext.Machine.Spec.Bootstrap.DataSecretName
-		machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: machineContext.Machine.GetNamespace(), Name: *machineBootstrapSecretReferenceName + "-userdata"}
+		// machineBootstrapSecretReferenceName := machineContext.Machine.Spec.Bootstrap.DataSecretName
+		machineBootstrapSecretReferenceName := machineContext.Machine.Name
+		// machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: machineContext.Machine.GetNamespace(), Name: *machineBootstrapSecretReferenceName + "-userdata"}
+		machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: machineContext.Machine.GetNamespace(), Name: machineBootstrapSecretReferenceName + "-userdata"}
 		infraClusterClient, _, err := infraClusterMock.GenerateInfraClusterClient(kubevirtMachine.Spec.InfraClusterSecretRef, kubevirtMachine.Namespace, machineContext.Context)
 		Expect(err).NotTo(HaveOccurred())
 		bootstrapDataSecret := &corev1.Secret{}
@@ -497,8 +507,10 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 		vmKey := client.ObjectKey{Namespace: kubevirtMachine.Namespace, Name: kubevirtMachine.Name}
 		Expect(fakeClient.Get(gocontext.Background(), vmKey, vm)).To(Succeed())
 
-		machineBootstrapSecretReferenceName := machineContext.Machine.Spec.Bootstrap.DataSecretName
-		machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: machineContext.Machine.GetNamespace(), Name: *machineBootstrapSecretReferenceName + "-userdata"}
+		// machineBootstrapSecretReferenceName := machineContext.Machine.Spec.Bootstrap.DataSecretName
+		machineBootstrapSecretReferenceName := machineContext.Machine.Name
+		// machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: machineContext.Machine.GetNamespace(), Name: *machineBootstrapSecretReferenceName + "-userdata"}
+		machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: machineContext.Machine.GetNamespace(), Name: machineBootstrapSecretReferenceName + "-userdata"}
 		infraClusterClient, _, err := infraClusterMock.GenerateInfraClusterClient(kubevirtMachine.Spec.InfraClusterSecretRef, kubevirtMachine.Namespace, machineContext.Context)
 		Expect(err).NotTo(HaveOccurred())
 
@@ -554,6 +566,7 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 			machine,
 			kubevirtMachine,
 			bootstrapSecret,
+			bootstrapUserDataSecret,
 		}
 
 		setupClient(kubevirt.DefaultMachineFactory{}, objects)
@@ -577,14 +590,17 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 		Expect(machineContext.KubevirtMachine.Spec.ProviderID).To(BeNil())
 
 		// Should have created the userdata secret
-		machineBootstrapSecretReferenceName := machineContext.Machine.Spec.Bootstrap.DataSecretName
-		machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: kubevirtMachine.Namespace, Name: *machineBootstrapSecretReferenceName + "-userdata"}
+		// machineBootstrapSecretReferenceName := machineContext.Machine.Spec.Bootstrap.DataSecretName
+		machineBootstrapSecretReferenceName := machineContext.Machine.Name
+		// machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: machineContext.Machine.GetNamespace(), Name: *machineBootstrapSecretReferenceName + "-userdata"}
+		machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: machineContext.Machine.GetNamespace(), Name: machineBootstrapSecretReferenceName + "-userdata"}
 		bootstrapDataSecret := &corev1.Secret{}
 		Expect(
 			fakeClient.Get(gocontext.Background(), machineBootstrapSecretReferenceKey, bootstrapDataSecret),
 		).To(Succeed())
 		Expect(bootstrapDataSecret.Data).To(HaveKeyWithValue("userdata", []byte("shell-script")))
-		Expect(bootstrapDataSecret.Labels).To(HaveLen(1))
+		// Expect(bootstrapDataSecret.Labels).To(HaveLen(1))
+		Expect(bootstrapDataSecret.Labels).To(HaveLen(2))
 		Expect(bootstrapDataSecret.Labels).To(HaveKeyWithValue("hello", "world"))
 	})
 
@@ -593,6 +609,19 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 		customNamespace := "custom"
 		kubevirtMachine.Spec.VirtualMachineTemplate.ObjectMeta.Namespace = customNamespace
 
+		// Create the bootstrap userdata secret in the custom namespace
+		// The controller expects: bootstrapSecretName + "-userdata"
+		customBootstrapUserDataSecret := &corev1.Secret{
+			ObjectMeta: metav1.ObjectMeta{
+				Name:      bootstrapSecretName + "-userdata", // "bootstrap-secret-userdata"
+				Namespace: customNamespace,                   // Important: in custom namespace
+				Labels:    map[string]string{"hello": "world"},
+			},
+			Data: map[string][]byte{
+				"userdata": []byte("shell-script"),
+			},
+		}
+
 		objects := []client.Object{
 			cluster,
 			kubevirtCluster,
@@ -600,6 +629,7 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 			kubevirtMachine,
 			sshKeySecret,
 			bootstrapSecret,
+			customBootstrapUserDataSecret,
 		}
 
 		setupClient(kubevirt.DefaultMachineFactory{}, objects)
@@ -623,12 +653,15 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 		Expect(machineContext.KubevirtMachine.Spec.ProviderID).To(BeNil())
 
 		// Should have created the userdata secret
-		machineBootstrapSecretReferenceName := machineContext.Machine.Spec.Bootstrap.DataSecretName
-		machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: customNamespace, Name: *machineBootstrapSecretReferenceName + "-userdata"}
+		// machineBootstrapSecretReferenceName := machineContext.Machine.Spec.Bootstrap.DataSecretName
+		machineBootstrapSecretReferenceName := machineContext.Machine.Name
+		// machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: customNamespace, Name: *machineBootstrapSecretReferenceName + "-userdata"}
+		machineBootstrapSecretReferenceKey := client.ObjectKey{Namespace: customNamespace, Name: machineBootstrapSecretReferenceName + "-userdata"}
 		bootstrapDataSecret := &corev1.Secret{}
 		Expect(fakeClient.Get(gocontext.Background(), machineBootstrapSecretReferenceKey, bootstrapDataSecret)).To(Succeed())
 		Expect(bootstrapDataSecret.Data).To(HaveKeyWithValue("userdata", []byte("shell-script")))
-		Expect(bootstrapDataSecret.Labels).To(HaveLen(1))
+		// Expect(bootstrapDataSecret.Labels).To(HaveLen(1))
+		Expect(bootstrapDataSecret.Labels).To(HaveLen(2))
 		Expect(bootstrapDataSecret.Labels).To(HaveKeyWithValue("hello", "world"))
 	})
 
@@ -905,6 +938,27 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 			})
 
 			It("adds a failed VMProvisionedCondition with reason VMCreateFailed when failing to create VM", func() {
+				// Set explicit namespace for both machine and bootstrap secret
+				testNamespace := "default"
+				machine.Namespace = testNamespace
+				kubevirtMachine.Namespace = testNamespace
+				kubevirtCluster.Namespace = testNamespace
+				cluster.Namespace = testNamespace
+				bootstrapSecret.Namespace = testNamespace
+				sshKeySecret.Namespace = testNamespace
+
+				// Add the bootstrap-userdata secret so reconcileKubevirtBootstrapSecret succeeds
+				bootstrapUserDataSecret := &corev1.Secret{
+					ObjectMeta: metav1.ObjectMeta{
+						Name:      machine.Name + "-userdata",
+						Namespace: testNamespace,
+						Labels:    map[string]string{"hello": "world"},
+					},
+					Data: map[string][]byte{
+						"userdata": []byte("some valid cloud-init userdata"),
+					},
+				}
+
 				objects := []client.Object{
 					cluster,
 					kubevirtCluster,
@@ -912,6 +966,7 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 					kubevirtMachine,
 					sshKeySecret,
 					bootstrapSecret,
+					bootstrapUserDataSecret,
 				}
 
 				injectErr := interceptor.Funcs{
@@ -968,6 +1023,7 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 				machineMock.EXPECT().Address().Return("1.1.1.1").Times(1)
 				machineMock.EXPECT().SupportsCheckingIsBootstrapped().Return(false).Times(1)
 				machineMock.EXPECT().DrainNodeIfNeeded(gomock.Any()).Return(time.Duration(0), nil)
+				machineMock.EXPECT().GetConditions().Return([]kubevirtv1.VirtualMachineCondition{}).Times(1)
 				machineMock.EXPECT().IsLiveMigratable().Return(false, "", "", nil).Times(1)
 
 				machineFactoryMock.EXPECT().NewMachine(gomock.Any(), gomock.Any(), gomock.Any(), gomock.Any()).Return(machineMock, nil).Times(1)
@@ -1068,6 +1124,7 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 				machineMock.EXPECT().SupportsCheckingIsBootstrapped().Return(true)
 				machineMock.EXPECT().IsBootstrapped().Return(true)
 				machineMock.EXPECT().DrainNodeIfNeeded(gomock.Any()).Return(time.Duration(0), nil)
+				machineMock.EXPECT().GetConditions().Return([]kubevirtv1.VirtualMachineCondition{}).Times(1)
 				machineMock.EXPECT().IsLiveMigratable().Return(false, "", "", nil).Times(1)
 
 				machineFactoryMock.EXPECT().NewMachine(gomock.Any(), gomock.Any(), gomock.Any(), gomock.Any()).Return(machineMock, nil).Times(1)
@@ -1125,6 +1182,7 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 				machineMock.EXPECT().IsBootstrapped().Return(true)
 				machineMock.EXPECT().DrainNodeIfNeeded(gomock.Any()).Return(time.Duration(0), nil)
 				machineMock.EXPECT().IsLiveMigratable().Return(true, "", "", nil).Times(1)
+				machineMock.EXPECT().GetConditions().Return([]kubevirtv1.VirtualMachineCondition{}).Times(1)
 
 				machineFactoryMock.EXPECT().NewMachine(gomock.Any(), gomock.Any(), gomock.Any(), gomock.Any()).Return(machineMock, nil).Times(1)
 
@@ -1134,7 +1192,6 @@ var _ = Describe("reconcile a kubevirt machine", func() {
 
 				_, err := kubevirtMachineReconciler.reconcileNormal(machineContext)
 				Expect(err).ShouldNot(HaveOccurred())
-
 				conditions := machineContext.KubevirtMachine.GetConditions()
 
 				Expect(conditions[0].Type).To(Equal(infrav1.BootstrapExecSucceededCondition))
@@ -1345,6 +1402,7 @@ var _ = Describe("updateNodeProviderID", func() {
 		fakeClient = fake.NewClientBuilder().WithScheme(testing.SetupScheme()).WithObjects(objects...).Build()
 		kubevirtMachineReconciler = KubevirtMachineReconciler{
 			Client:                 fakeClient,
+			DirectClient:           fakeClient,
 			WorkloadCluster:        workloadClusterMock,
 			InfraCluster:           infraClusterMock,
 			getOwnerMachine:        util.GetOwnerMachine,
diff --git a/main.go b/main.go
index 24757cf..125d0aa 100644
--- a/main.go
+++ b/main.go
@@ -237,6 +237,7 @@ func setupReconcilers(ctx context.Context, mgr ctrl.Manager) {
 
 	if err := (&controllers.KubevirtMachineReconciler{
 		Client:          mgr.GetClient(),
+		DirectClient:    noCachedClient,
 		InfraCluster:    infracluster.New(mgr.GetClient(), noCachedClient),
 		WorkloadCluster: workloadcluster.New(mgr.GetClient()),
 		MachineFactory:  kubevirt.DefaultMachineFactory{},
diff --git a/pkg/kubevirt/machine.go b/pkg/kubevirt/machine.go
index 43401cc..2fb2a0f 100644
--- a/pkg/kubevirt/machine.go
+++ b/pkg/kubevirt/machine.go
@@ -257,6 +257,11 @@ func (m *Machine) IsLiveMigratable() (bool, string, string, error) {
 		m.vmiInstance.Status.Phase, kubevirtv1.VirtualMachineInstanceIsMigratable)
 }
 
+// GetConditions returns the VM conditions
+func (m *Machine) GetConditions() []kubevirtv1.VirtualMachineCondition {
+	return m.vmInstance.Status.Conditions
+}
+
 const (
 	defaultCondReason  = "VMNotReady"
 	defaultCondMessage = "VM is not ready"
diff --git a/pkg/kubevirt/machine_factory.go b/pkg/kubevirt/machine_factory.go
index d5724df..534c7e8 100644
--- a/pkg/kubevirt/machine_factory.go
+++ b/pkg/kubevirt/machine_factory.go
@@ -7,6 +7,7 @@ import (
 	"time"
 
 	"github.com/pkg/errors"
+	kubevirtv1 "kubevirt.io/api/core/v1"
 	"sigs.k8s.io/controller-runtime/pkg/client"
 
 	"sigs.k8s.io/cluster-api-provider-kubevirt/pkg/context"
@@ -38,6 +39,8 @@ type MachineInterface interface {
 	GenerateProviderID() (string, error)
 	// IsTerminal reports back if a VM is in a permanent terminal state
 	IsTerminal() (bool, string, error)
+	// GetConditions returns the conditions of the VM
+	GetConditions() []kubevirtv1.VirtualMachineCondition
 
 	DrainNodeIfNeeded(workloadcluster.WorkloadCluster) (time.Duration, error)
 
diff --git a/pkg/kubevirt/mock/machine_factory_generated.go b/pkg/kubevirt/mock/machine_factory_generated.go
index 2846f6b..9c7365e 100644
--- a/pkg/kubevirt/mock/machine_factory_generated.go
+++ b/pkg/kubevirt/mock/machine_factory_generated.go
@@ -10,12 +10,12 @@ import (
 	time "time"
 
 	gomock "github.com/golang/mock/gomock"
-	client "sigs.k8s.io/controller-runtime/pkg/client"
-
+	v1 "kubevirt.io/api/core/v1"
 	context0 "sigs.k8s.io/cluster-api-provider-kubevirt/pkg/context"
 	kubevirt "sigs.k8s.io/cluster-api-provider-kubevirt/pkg/kubevirt"
 	ssh "sigs.k8s.io/cluster-api-provider-kubevirt/pkg/ssh"
 	workloadcluster "sigs.k8s.io/cluster-api-provider-kubevirt/pkg/workloadcluster"
+	client "sigs.k8s.io/controller-runtime/pkg/client"
 )
 
 // MockMachineInterface is a mock of MachineInterface interface.
@@ -127,9 +127,33 @@ func (mr *MockMachineInterfaceMockRecorder) GenerateProviderID() *gomock.Call {
 	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "GenerateProviderID", reflect.TypeOf((*MockMachineInterface)(nil).GenerateProviderID))
 }
 
+// GetConditions mocks base method.
+func (m *MockMachineInterface) GetConditions() []v1.VirtualMachineCondition {
+	m.ctrl.T.Helper()
+	ret := m.ctrl.Call(m, "GetConditions")
+	ret0, _ := ret[0].([]v1.VirtualMachineCondition)
+	return ret0
+}
+
+// GetConditions indicates an expected call of GetConditions.
+func (mr *MockMachineInterfaceMockRecorder) GetConditions() *gomock.Call {
+	mr.mock.ctrl.T.Helper()
+	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "GetConditions", reflect.TypeOf((*MockMachineInterface)(nil).GetConditions))
+}
+
 // GetVMNotReadyReason mocks base method.
 func (m *MockMachineInterface) GetVMNotReadyReason() (string, string) {
-	return "", ""
+	m.ctrl.T.Helper()
+	ret := m.ctrl.Call(m, "GetVMNotReadyReason")
+	ret0, _ := ret[0].(string)
+	ret1, _ := ret[1].(string)
+	return ret0, ret1
+}
+
+// GetVMNotReadyReason indicates an expected call of GetVMNotReadyReason.
+func (mr *MockMachineInterfaceMockRecorder) GetVMNotReadyReason() *gomock.Call {
+	mr.mock.ctrl.T.Helper()
+	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "GetVMNotReadyReason", reflect.TypeOf((*MockMachineInterface)(nil).GetVMNotReadyReason))
 }
 
 // IsBootstrapped mocks base method.
-- 
2.49.0