From 5bc8e72e5fcbd8ae2d3d9bc78a1c0ef0040bcc39 Mon Sep 17 00:00:00 2001
From: Sean McArthur <sean@seanmonstar.com>
Date: Wed, 12 Apr 2023 12:23:56 -0400
Subject: [PATCH] fix: limit the amount of pending-accept reset streams

Streams that have been received by the peer, but not accepted by the
user, can also receive a RST_STREAM. This is a legitimate pattern: one
could send a request and then shortly after, realize it is not needed,
sending a CANCEL.

However, since those streams are now "closed", they don't count towards
the max concurrent streams. So, they will sit in the accept queue, using
memory.

In most cases, the user is calling `accept` in a loop, and they can
accept requests that have been reset fast enough that this isn't an
issue in practice.

But if the peer is able to flood the network faster than the server
accept loop can run (simply accepting, not processing requests; that
tends to happen in a separate task), the memory could grow.

So, this introduces a maximum count for streams in the pending-accept
but remotely-reset state. If the maximum is reached, a GOAWAY frame with
the error code of ENHANCE_YOUR_CALM is sent, and the connection marks
itself as errored.

ref CVE-2023-26964
ref GHSA-f8vr-r385-rh5r

Closes https://github.com/hyperium/hyper/issues/2877
---
 vendor/h2/.cargo-checksum.json         |  2 +-
 vendor/h2/src/client.rs                | 49 ++++++++++++++++++++++
 vendor/h2/src/proto/connection.rs      |  9 ++++-
 vendor/h2/src/proto/mod.rs             |  1 +
 vendor/h2/src/proto/streams/counts.rs  | 53 +++++++++++++++++++-----
 vendor/h2/src/proto/streams/mod.rs     |  4 ++
 vendor/h2/src/proto/streams/recv.rs    | 29 ++++++++++++-
 vendor/h2/src/proto/streams/state.rs   |  7 ++++
 vendor/h2/src/proto/streams/streams.rs |  8 +++-
 vendor/h2/src/server.rs                | 56 ++++++++++++++++++++++++++
 10 files changed, 204 insertions(+), 14 deletions(-)

diff --git a/vendor/h2/.cargo-checksum.json b/vendor/h2/.cargo-checksum.json
index 15f2233f..d2286e4d 100644
--- a/vendor/h2/.cargo-checksum.json
+++ b/vendor/h2/.cargo-checksum.json
@@ -1 +1 @@
-{"files":{"CHANGELOG.md":"c4ff0f1f71a1527093a63af4678bca296d6617f5daf7bd9ace5ebeec2ff68cef","CONTRIBUTING.md":"eff9610bd3a73e6c297b9b487a629bcdb40da9090e6e28c26e48fcfd3a899a6c","Cargo.lock":"b27ce095023ad9bffc680d4f6b7b377863a37b2b551dab1548ab4c8d40a10d3b","Cargo.toml":"e9f82adcb5f9d5b440693a3534ada6bb259b9ac7d67cb514a8374fc8e9546238","LICENSE":"b21623012e6c453d944b0342c515b631cfcbf30704c2621b291526b69c10724d","README.md":"1c23aebc383c31dd70a14880c93ec2ddac0001aa4ba1d8f3c5b0a9897fa5ef11","examples/akamai.rs":"f8d310ba4ba0364f887746071f76f566fdffa3b0959050ec07c47afeeb8786d4","examples/client.rs":"5ad136b838e9d55ae3d1fd8801cec4af88139b58864d6438f75d0e173eb3aeb3","examples/server.rs":"14c354d505fd82917efb8077f1aeb430ac8c56de3ef6a22602ab206727b4213d","src/client.rs":"c23d51eba494dce6660f435ffe55688480f16f6f1e5d3350c86e05805480bef0","src/codec/error.rs":"beb559466193d480f853cc0b26033667d01d9946239f74539dcf103d314c7ef4","src/codec/framed_read.rs":"e1b4e5b31fd17f2df98de7b7f29fd656643db4e70b2277e870500604cb6f0974","src/codec/framed_write.rs":"6ae09b84e8c6bf818f99c2ebcafe01073146a33bae090874d5f4221e6309d9ae","src/codec/mod.rs":"10ed96b6e187a86c827f066bb81b4047dbdff942f9cc7fab81bd37c989a8a9c1","src/error.rs":"445f810c0d9f3bdd2889792aac00d6af06363c0d8e5cb73a400ae39191cdefde","src/frame/data.rs":"65fbfe306d525df7ac0ba229ca75ec3d142203ec62ddd3df0b8452da1496da3e","src/frame/go_away.rs":"f76843de59a0e3e82536972af7754498c3913577ee248a6e1601df2b68e06c96","src/frame/head.rs":"9cde126609db8ddd1e27b8212af3a613a1d59461166567ae1c97fcba7902f2fe","src/frame/headers.rs":"49ba7b0c5d25d890ae23dd0ce047ff38e0e909eacb0813c05ebc5e8bc7896020","src/frame/mod.rs":"f1baebdfff10c0f1d9937681b0f21df8631196c285aa860516235d49275ae90f","src/frame/ping.rs":"ff4e4059101300e7b03c23d271026b058da4315c3bd68280422e144c2aa1b9e6","src/frame/priority.rs":"9392b7aa2636157024dc645c92d0e450a4d3f7a53bc9de1188d3b61178c2b5fc","src/frame/reason.rs":"4337f5933bfd4064337c80d3c110f51514cbdfb97bc26f4980ee009e4f6fa773","src/frame/reset.rs":"7dceecf432ee82bea3f02ce50065350f6f7cf02f98378e7608568e3eb5bf913a","src/frame/settings.rs":"c769341d0fb009a3d7e57862a371dd223028f327628b466b2c22368c8ca06b26","src/frame/stream_id.rs":"0aa72cc3d735aa31e4d0cca0a8b94bae75c97d041c3712fe8e49f687881a73fe","src/frame/util.rs":"1a1408ddefe35f9efe5faa5360cb5ecc461fc0846175d4b43031720da7f5188d","src/frame/window_update.rs":"05c1b84478208802d09154f5d6fb5eb886d45397f43ccc6ccbf40bf3be912819","src/fuzz_bridge.rs":"a233d7c986671a91fd84af996a281068814e6d3a1fd7f22a77e4b4cd54a0d773","src/hpack/decoder.rs":"d5955341d436e8dece258dd66b3373249cfc2473e4484a0d5d57fa5e6b8776f4","src/hpack/encoder.rs":"ca2b76e9d7d8fdc1b8d482a72b6a886516f4f641fe88b2ea3d237051c11fe7ca","src/hpack/header.rs":"d5b5ed925d4cf06b13a765d34f858004d1dd0003fd2e1d35d7927f86cf34f1dc","src/hpack/huffman/mod.rs":"04fc9b146177e7bf615156b8570fa0f97b89f68a2c02b946778711728b81e81f","src/hpack/huffman/table.rs":"6b7f94af0bb5d236d4e671eff4afe5dc254a20eaddd2d57dd6e8f53e2a60c337","src/hpack/mod.rs":"702a0b41ef5aa9e83683cec25363fb4f9c0f61c6697f9def9994967440fea378","src/hpack/table.rs":"c76073d0cf07e6379b4d4b26bc3883b69d7c5555dd1c0c38a5e2c69b80e59330","src/hpack/test/fixture.rs":"9ab6b0ed15fa3643e012bd2742e89ecf7aab821e2d0713dc6835c332611f2ec7","src/hpack/test/fuzz.rs":"83daceb07b9c4ad5330df01c5c9de63d9da8cc91ac590ae40f108166ef150c48","src/hpack/test/mod.rs":"56ad5643e7f1e273e5bce8a6fc0552be39c326dacfffd7f9757ccdbe75e9b66e","src/lib.rs":"d4692389a49d909184adda23479c006bb3e9e165be549cffa93860fcb88d3ea6","src/proto/connection.rs":"fe7efe1bb8a329ce093505be4012b3b496d8dedf4632e3e33e7135a4872dc601","src/proto/error.rs":"7486777b6d9f13c9df3e4a921196e6d16ae45922b4e34aa15282876198d1ebf7","src/proto/go_away.rs":"16fdecca841ce046960d29ca03a3dbf61886e4b7b9532217dde493ebcdc10477","src/proto/mod.rs":"9a858c0c937cc9209b6cb5c0feeaf41ec116d58e2c3c7483fa7460e3e66bf0f3","src/proto/peer.rs":"6047ab139e774d50fc4def41508869a6fed950007825d3e76141840d4b01dcff","src/proto/ping_pong.rs":"eb4757f4ba7e4f323d38724e1a09476c29efda01c5606af8e1b6e91942af45e1","src/proto/settings.rs":"4b2cd95dbde4b4caf750d3761221cf680d1830247a18f18fb778e7b9f2c54263","src/proto/streams/buffer.rs":"cf2205c607f8a6b8aa8662983d9907fedeb14b5890e051d8e63d7bc2b0a960e9","src/proto/streams/counts.rs":"46e9e574d1c804b0b3a426c393a81867d8a10f553859b4964dbfd9ef9a44ee94","src/proto/streams/flow_control.rs":"bb85d9848b798b15a5f6d692bf2b6345d0aecccf43adfc431d6bef44a152d301","src/proto/streams/mod.rs":"72cd11d368ba26b65abae838ad1d7baf15ba338d57e61ceed9d62d182cb58f8c","src/proto/streams/prioritize.rs":"62caf7b502849a15a37d0fb06315b833bc816506a1cc359a6d377c84e7ffbedc","src/proto/streams/recv.rs":"e0795574db6dd8e0eecb78bf72507af6cbc0e7b85d320ffd4de925ffc78ac2df","src/proto/streams/send.rs":"2fcff0e988daf1c84d2a4b008ae651b17d8c83aa6060133e98579ee678b9fec2","src/proto/streams/state.rs":"85db4958e88e25a2905186ff04c4daf6c9061b237e3b05fece26721dae7e2541","src/proto/streams/store.rs":"75c6b6f8d6fe3f2a4ddc2e821fbad4be7a813f2ed04ee7f423ad622cbec43a83","src/proto/streams/stream.rs":"e948c7c34472b934e87b6dc5ddc624a5e4d98b3cb6aed287bf843b5f775a6bfc","src/proto/streams/streams.rs":"07e748f2de2bd5fe9aa2e53201472e3e48e1779f4ae68712c058e22acc4d0daf","src/server.rs":"21b559cc0aa6018880b78ff4000d2fd258b5281902ea8b245a525693b878b704","src/share.rs":"0f8629a40390a62e34e9ab5b0590877af5616e48a70bde484af469de23053f7d"},"package":"825343c4eef0b63f541f8903f395dc5beb362a979b5799a84062527ef1e37726"}
\ No newline at end of file
+{"files":{"CHANGELOG.md":"c4ff0f1f71a1527093a63af4678bca296d6617f5daf7bd9ace5ebeec2ff68cef","CONTRIBUTING.md":"eff9610bd3a73e6c297b9b487a629bcdb40da9090e6e28c26e48fcfd3a899a6c","Cargo.lock":"b27ce095023ad9bffc680d4f6b7b377863a37b2b551dab1548ab4c8d40a10d3b","Cargo.toml":"e9f82adcb5f9d5b440693a3534ada6bb259b9ac7d67cb514a8374fc8e9546238","LICENSE":"b21623012e6c453d944b0342c515b631cfcbf30704c2621b291526b69c10724d","README.md":"1c23aebc383c31dd70a14880c93ec2ddac0001aa4ba1d8f3c5b0a9897fa5ef11","examples/akamai.rs":"f8d310ba4ba0364f887746071f76f566fdffa3b0959050ec07c47afeeb8786d4","examples/client.rs":"5ad136b838e9d55ae3d1fd8801cec4af88139b58864d6438f75d0e173eb3aeb3","examples/server.rs":"14c354d505fd82917efb8077f1aeb430ac8c56de3ef6a22602ab206727b4213d","src/client.rs":"ed9a09e3be56391d5f83bad45ffcf650e9b7dc92001706a126fc18ff981a38f3","src/codec/error.rs":"beb559466193d480f853cc0b26033667d01d9946239f74539dcf103d314c7ef4","src/codec/framed_read.rs":"e1b4e5b31fd17f2df98de7b7f29fd656643db4e70b2277e870500604cb6f0974","src/codec/framed_write.rs":"6ae09b84e8c6bf818f99c2ebcafe01073146a33bae090874d5f4221e6309d9ae","src/codec/mod.rs":"10ed96b6e187a86c827f066bb81b4047dbdff942f9cc7fab81bd37c989a8a9c1","src/error.rs":"445f810c0d9f3bdd2889792aac00d6af06363c0d8e5cb73a400ae39191cdefde","src/frame/data.rs":"65fbfe306d525df7ac0ba229ca75ec3d142203ec62ddd3df0b8452da1496da3e","src/frame/go_away.rs":"f76843de59a0e3e82536972af7754498c3913577ee248a6e1601df2b68e06c96","src/frame/head.rs":"9cde126609db8ddd1e27b8212af3a613a1d59461166567ae1c97fcba7902f2fe","src/frame/headers.rs":"49ba7b0c5d25d890ae23dd0ce047ff38e0e909eacb0813c05ebc5e8bc7896020","src/frame/mod.rs":"f1baebdfff10c0f1d9937681b0f21df8631196c285aa860516235d49275ae90f","src/frame/ping.rs":"ff4e4059101300e7b03c23d271026b058da4315c3bd68280422e144c2aa1b9e6","src/frame/priority.rs":"9392b7aa2636157024dc645c92d0e450a4d3f7a53bc9de1188d3b61178c2b5fc","src/frame/reason.rs":"4337f5933bfd4064337c80d3c110f51514cbdfb97bc26f4980ee009e4f6fa773","src/frame/reset.rs":"7dceecf432ee82bea3f02ce50065350f6f7cf02f98378e7608568e3eb5bf913a","src/frame/settings.rs":"c769341d0fb009a3d7e57862a371dd223028f327628b466b2c22368c8ca06b26","src/frame/stream_id.rs":"0aa72cc3d735aa31e4d0cca0a8b94bae75c97d041c3712fe8e49f687881a73fe","src/frame/util.rs":"1a1408ddefe35f9efe5faa5360cb5ecc461fc0846175d4b43031720da7f5188d","src/frame/window_update.rs":"05c1b84478208802d09154f5d6fb5eb886d45397f43ccc6ccbf40bf3be912819","src/fuzz_bridge.rs":"a233d7c986671a91fd84af996a281068814e6d3a1fd7f22a77e4b4cd54a0d773","src/hpack/decoder.rs":"d5955341d436e8dece258dd66b3373249cfc2473e4484a0d5d57fa5e6b8776f4","src/hpack/encoder.rs":"ca2b76e9d7d8fdc1b8d482a72b6a886516f4f641fe88b2ea3d237051c11fe7ca","src/hpack/header.rs":"d5b5ed925d4cf06b13a765d34f858004d1dd0003fd2e1d35d7927f86cf34f1dc","src/hpack/huffman/mod.rs":"04fc9b146177e7bf615156b8570fa0f97b89f68a2c02b946778711728b81e81f","src/hpack/huffman/table.rs":"6b7f94af0bb5d236d4e671eff4afe5dc254a20eaddd2d57dd6e8f53e2a60c337","src/hpack/mod.rs":"702a0b41ef5aa9e83683cec25363fb4f9c0f61c6697f9def9994967440fea378","src/hpack/table.rs":"c76073d0cf07e6379b4d4b26bc3883b69d7c5555dd1c0c38a5e2c69b80e59330","src/hpack/test/fixture.rs":"9ab6b0ed15fa3643e012bd2742e89ecf7aab821e2d0713dc6835c332611f2ec7","src/hpack/test/fuzz.rs":"83daceb07b9c4ad5330df01c5c9de63d9da8cc91ac590ae40f108166ef150c48","src/hpack/test/mod.rs":"56ad5643e7f1e273e5bce8a6fc0552be39c326dacfffd7f9757ccdbe75e9b66e","src/lib.rs":"d4692389a49d909184adda23479c006bb3e9e165be549cffa93860fcb88d3ea6","src/proto/connection.rs":"62a59c8ea8a3f7ea2849a895a99182e846450bcbad876b0efdc57aba604e75e6","src/proto/error.rs":"7486777b6d9f13c9df3e4a921196e6d16ae45922b4e34aa15282876198d1ebf7","src/proto/go_away.rs":"16fdecca841ce046960d29ca03a3dbf61886e4b7b9532217dde493ebcdc10477","src/proto/mod.rs":"b25ae834a7253d520c684acba0e75a40eb1711b3a43bee56269b685bc1dc2447","src/proto/peer.rs":"6047ab139e774d50fc4def41508869a6fed950007825d3e76141840d4b01dcff","src/proto/ping_pong.rs":"eb4757f4ba7e4f323d38724e1a09476c29efda01c5606af8e1b6e91942af45e1","src/proto/settings.rs":"4b2cd95dbde4b4caf750d3761221cf680d1830247a18f18fb778e7b9f2c54263","src/proto/streams/buffer.rs":"cf2205c607f8a6b8aa8662983d9907fedeb14b5890e051d8e63d7bc2b0a960e9","src/proto/streams/counts.rs":"23e984a270372936ab43da3c44d79d85d78f181ef0056e8b4824b51f062fd748","src/proto/streams/flow_control.rs":"bb85d9848b798b15a5f6d692bf2b6345d0aecccf43adfc431d6bef44a152d301","src/proto/streams/mod.rs":"94e9d2592d93f92da9cacc697ea7ba0beafe01ca5dae91061b40e52463679a8d","src/proto/streams/prioritize.rs":"62caf7b502849a15a37d0fb06315b833bc816506a1cc359a6d377c84e7ffbedc","src/proto/streams/recv.rs":"ee346806c65da77c6309cd629e2ac7e49d8d1913b4baaa2d360ed11757ecc6c1","src/proto/streams/send.rs":"2fcff0e988daf1c84d2a4b008ae651b17d8c83aa6060133e98579ee678b9fec2","src/proto/streams/state.rs":"fbddd27c1b706fce7d841b4a01ffa06acd020839fcea49d1b4debc908b6ad0db","src/proto/streams/store.rs":"75c6b6f8d6fe3f2a4ddc2e821fbad4be7a813f2ed04ee7f423ad622cbec43a83","src/proto/streams/stream.rs":"e948c7c34472b934e87b6dc5ddc624a5e4d98b3cb6aed287bf843b5f775a6bfc","src/proto/streams/streams.rs":"248d62f2c368606cb1d77b5d9e588f164a92713ac17128811a07667116d888c1","src/server.rs":"b251879976021363b924c3eadf44cf9f42233020e68455dd51e6d5fc1c78c218","src/share.rs":"0f8629a40390a62e34e9ab5b0590877af5616e48a70bde484af469de23053f7d"},"package":"825343c4eef0b63f541f8903f395dc5beb362a979b5799a84062527ef1e37726"}
diff --git a/vendor/h2/src/client.rs b/vendor/h2/src/client.rs
index 5bbbaf49..0d553d8b 100644
--- a/vendor/h2/src/client.rs
+++ b/vendor/h2/src/client.rs
@@ -322,6 +322,10 @@ pub struct Builder {
     /// Maximum number of locally reset streams to keep at a time.
     reset_stream_max: usize,
 
+    /// Maximum number of remotely reset streams to allow in the pending
+    /// accept queue.
+    pending_accept_reset_stream_max: usize,
+
     /// Initial `Settings` frame to send as part of the handshake.
     settings: Settings,
 
@@ -616,6 +620,7 @@ impl Builder {
         Builder {
             reset_stream_duration: Duration::from_secs(proto::DEFAULT_RESET_STREAM_SECS),
             reset_stream_max: proto::DEFAULT_RESET_STREAM_MAX,
+            pending_accept_reset_stream_max: proto::DEFAULT_REMOTE_RESET_STREAM_MAX,
             initial_target_connection_window_size: None,
             initial_max_send_streams: usize::MAX,
             settings: Default::default(),
@@ -948,6 +953,49 @@ impl Builder {
         self
     }
 
+    /// Sets the maximum number of pending-accept remotely-reset streams.
+    ///
+    /// Streams that have been received by the peer, but not accepted by the
+    /// user, can also receive a RST_STREAM. This is a legitimate pattern: one
+    /// could send a request and then shortly after, realize it is not needed,
+    /// sending a CANCEL.
+    ///
+    /// However, since those streams are now "closed", they don't count towards
+    /// the max concurrent streams. So, they will sit in the accept queue,
+    /// using memory.
+    ///
+    /// When the number of remotely-reset streams sitting in the pending-accept
+    /// queue reaches this maximum value, a connection error with the code of
+    /// `ENHANCE_YOUR_CALM` will be sent to the peer, and returned by the
+    /// `Future`.
+    ///
+    /// The default value is currently 20, but could change.
+    ///
+    /// # Examples
+    ///
+    /// ```
+    /// # use tokio::io::{AsyncRead, AsyncWrite};
+    /// # use h2::client::*;
+    /// # use bytes::Bytes;
+    /// #
+    /// # async fn doc<T: AsyncRead + AsyncWrite + Unpin>(my_io: T)
+    /// # -> Result<((SendRequest<Bytes>, Connection<T, Bytes>)), h2::Error>
+    /// # {
+    /// // `client_fut` is a future representing the completion of the HTTP/2
+    /// // handshake.
+    /// let client_fut = Builder::new()
+    ///     .max_pending_accept_reset_streams(100)
+    ///     .handshake(my_io);
+    /// # client_fut.await
+    /// # }
+    /// #
+    /// # pub fn main() {}
+    /// ```
+    pub fn max_pending_accept_reset_streams(&mut self, max: usize) -> &mut Self {
+        self.pending_accept_reset_stream_max = max;
+        self
+    }
+
     /// Enables or disables server push promises.
     ///
     /// This value is included in the initial SETTINGS handshake. When set, the
@@ -1172,6 +1220,7 @@ where
                 initial_max_send_streams: builder.initial_max_send_streams,
                 reset_stream_duration: builder.reset_stream_duration,
                 reset_stream_max: builder.reset_stream_max,
+                remote_reset_stream_max: builder.pending_accept_reset_stream_max,
                 settings: builder.settings.clone(),
             },
         );
diff --git a/vendor/h2/src/proto/connection.rs b/vendor/h2/src/proto/connection.rs
index b44fdcd5..37a0c8f0 100644
--- a/vendor/h2/src/proto/connection.rs
+++ b/vendor/h2/src/proto/connection.rs
@@ -13,7 +13,7 @@ use std::pin::Pin;
 use std::task::{Context, Poll};
 use std::time::Duration;
 use tokio::io::{AsyncRead, AsyncWrite};
-
+ 
 /// An H2 connection
 #[derive(Debug)]
 pub(crate) struct Connection<T, P, B: Buf = Bytes>
@@ -79,6 +79,7 @@ pub(crate) struct Config {
     pub initial_max_send_streams: usize,
     pub reset_stream_duration: Duration,
     pub reset_stream_max: usize,
+    pub remote_reset_stream_max: usize,
     pub settings: frame::Settings,
 }
 
@@ -112,6 +113,7 @@ where
                 local_push_enabled: config.settings.is_push_enabled().unwrap_or(true),
                 local_reset_duration: config.reset_stream_duration,
                 local_reset_max: config.reset_stream_max,
+                remote_reset_max: config.remote_reset_stream_max,
                 remote_init_window_sz: DEFAULT_INITIAL_WINDOW_SIZE,
                 remote_max_initiated: config
                     .settings
@@ -159,6 +161,11 @@ where
         self.inner.streams.max_recv_streams()
     }
 
+    #[cfg(feature = "unstable")]
+    pub fn num_wired_streams(&self) -> usize {
+        self.inner.streams.num_wired_streams()
+    }
+
     /// Returns `Ready` when the connection is ready to receive a frame.
     ///
     /// Returns `RecvError` as this may raise errors that are caused by delayed
diff --git a/vendor/h2/src/proto/mod.rs b/vendor/h2/src/proto/mod.rs
index 84fd8542..fcb461c6 100644
--- a/vendor/h2/src/proto/mod.rs
+++ b/vendor/h2/src/proto/mod.rs
@@ -31,5 +31,6 @@ pub type WindowSize = u32;
 
 // Constants
 pub const MAX_WINDOW_SIZE: WindowSize = (1 << 31) - 1;
+pub const DEFAULT_REMOTE_RESET_STREAM_MAX: usize = 20;
 pub const DEFAULT_RESET_STREAM_MAX: usize = 10;
 pub const DEFAULT_RESET_STREAM_SECS: u64 = 30;
diff --git a/vendor/h2/src/proto/streams/counts.rs b/vendor/h2/src/proto/streams/counts.rs
index 70dfc785..e41859f3 100644
--- a/vendor/h2/src/proto/streams/counts.rs
+++ b/vendor/h2/src/proto/streams/counts.rs
@@ -21,10 +21,16 @@ pub(super) struct Counts {
     num_recv_streams: usize,
 
     /// Maximum number of pending locally reset streams
-    max_reset_streams: usize,
-
+    max_local_reset_streams: usize,
+ 
     /// Current number of pending locally reset streams
-    num_reset_streams: usize,
+    num_local_reset_streams: usize,
+
+    /// Max number of "pending accept" streams that were remotely reset
+    max_remote_reset_streams: usize,
+
+    /// Current number of "pending accept" streams that were remotely reset
+    num_remote_reset_streams: usize,
 }
 
 impl Counts {
@@ -36,8 +42,10 @@ impl Counts {
             num_send_streams: 0,
             max_recv_streams: config.remote_max_initiated.unwrap_or(usize::MAX),
             num_recv_streams: 0,
-            max_reset_streams: config.local_reset_max,
-            num_reset_streams: 0,
+            max_local_reset_streams: config.local_reset_max,
+            num_local_reset_streams: 0,
+            max_remote_reset_streams: config.remote_reset_max,
+            num_remote_reset_streams: 0,
         }
     }
 
@@ -90,7 +98,7 @@ impl Counts {
 
     /// Returns true if the number of pending reset streams can be incremented.
     pub fn can_inc_num_reset_streams(&self) -> bool {
-        self.max_reset_streams > self.num_reset_streams
+        self.max_local_reset_streams > self.num_local_reset_streams
     }
 
     /// Increments the number of pending reset streams.
@@ -101,7 +109,34 @@ impl Counts {
     pub fn inc_num_reset_streams(&mut self) {
         assert!(self.can_inc_num_reset_streams());
 
-        self.num_reset_streams += 1;
+        self.num_local_reset_streams += 1;
+    }
+
+    pub(crate) fn max_remote_reset_streams(&self) -> usize {
+        self.max_remote_reset_streams
+    }
+
+    /// Returns true if the number of pending REMOTE reset streams can be
+    /// incremented.
+    pub(crate) fn can_inc_num_remote_reset_streams(&self) -> bool {
+        self.max_remote_reset_streams > self.num_remote_reset_streams
+    }
+
+    /// Increments the number of pending REMOTE reset streams.
+    ///
+    /// # Panics
+    ///
+    /// Panics on failure as this should have been validated before hand.
+    pub(crate) fn inc_num_remote_reset_streams(&mut self) {
+        assert!(self.can_inc_num_remote_reset_streams());
+
+        self.num_remote_reset_streams += 1;
+    }
+
+    pub(crate) fn dec_num_remote_reset_streams(&mut self) {
+        assert!(self.num_remote_reset_streams > 0);
+
+        self.num_remote_reset_streams -= 1;
     }
 
     pub fn apply_remote_settings(&mut self, settings: &frame::Settings) {
@@ -194,8 +229,8 @@ impl Counts {
     }
 
     fn dec_num_reset_streams(&mut self) {
-        assert!(self.num_reset_streams > 0);
-        self.num_reset_streams -= 1;
+        assert!(self.num_local_reset_streams > 0);
+        self.num_local_reset_streams -= 1;
     }
 }
 
diff --git a/vendor/h2/src/proto/streams/mod.rs b/vendor/h2/src/proto/streams/mod.rs
index 608395c0..6055ae53 100644
--- a/vendor/h2/src/proto/streams/mod.rs
+++ b/vendor/h2/src/proto/streams/mod.rs
@@ -53,6 +53,10 @@ pub struct Config {
     /// Maximum number of locally reset streams to keep at a time
     pub local_reset_max: usize,
 
+    /// Maximum number of remotely reset "pending accept" streams to keep at a
+    /// time. Going over this number results in a connection error.
+    pub remote_reset_max: usize,
+
     /// Initial window size of remote initiated streams
     pub remote_init_window_sz: WindowSize,
 
diff --git a/vendor/h2/src/proto/streams/recv.rs b/vendor/h2/src/proto/streams/recv.rs
index 252fd868..dbe89daa 100644
--- a/vendor/h2/src/proto/streams/recv.rs
+++ b/vendor/h2/src/proto/streams/recv.rs
@@ -745,7 +745,31 @@ impl Recv {
     }
 
     /// Handle remote sending an explicit RST_STREAM.
-    pub fn recv_reset(&mut self, frame: frame::Reset, stream: &mut Stream) {
+    pub fn recv_reset(
+        &mut self,
+        frame: frame::Reset,
+        stream: &mut Stream,
+        counts: &mut Counts,
+    ) -> Result<(), RecvError> {
+        // Reseting a stream that the user hasn't accepted is possible,
+        // but should be done with care. These streams will continue
+        // to take up memory in the accept queue, but will no longer be
+        // counted as "concurrent" streams.
+        //
+        // So, we have a separate limit for these.
+        //
+        // See https://github.com/hyperium/hyper/issues/2877
+        if stream.is_pending_accept {
+            if counts.can_inc_num_remote_reset_streams() {
+                counts.inc_num_remote_reset_streams();
+            } else {
+                tracing::warn!(
+                    "recv_reset; remotely-reset pending-accept streams reached limit ({:?})",
+                    counts.max_remote_reset_streams(),
+                );
+                return Err(RecvError::Connection(Reason::ENHANCE_YOUR_CALM));
+            }
+        }
         // Notify the stream
         stream
             .state
@@ -753,6 +777,8 @@ impl Recv {
 
         stream.notify_send();
         stream.notify_recv();
+
+        Ok(())
     }
 
     /// Handle a received error
@@ -1024,7 +1050,6 @@ impl Recv {
         cx: &Context,
         stream: &mut Stream,
     ) -> Poll<Option<Result<Bytes, proto::Error>>> {
-        // TODO: Return error when the stream is reset
         match stream.pending_recv.pop_front(&mut self.buffer) {
             Some(Event::Data(payload)) => Poll::Ready(Some(Ok(payload))),
             Some(event) => {
diff --git a/vendor/h2/src/proto/streams/state.rs b/vendor/h2/src/proto/streams/state.rs
index 3e739daf..b753d44f 100644
--- a/vendor/h2/src/proto/streams/state.rs
+++ b/vendor/h2/src/proto/streams/state.rs
@@ -362,6 +362,13 @@ impl State {
         }
     }
 
+    pub fn is_remote_reset(&self) -> bool {
+        match self.inner {
+            Closed(Cause::LocallyReset(_)) => true,
+            _ => false,
+        }
+    }
+
     /// Returns true if the stream is already reset.
     pub fn is_reset(&self) -> bool {
         match self.inner {
diff --git a/vendor/h2/src/proto/streams/streams.rs b/vendor/h2/src/proto/streams/streams.rs
index c694203a..1eadb5bb 100644
--- a/vendor/h2/src/proto/streams/streams.rs
+++ b/vendor/h2/src/proto/streams/streams.rs
@@ -140,6 +140,12 @@ where
             // TODO: ideally, OpaqueStreamRefs::new would do this, but we're holding
             // the lock, so it can't.
             me.refs += 1;
+
+            // Pending-accepted remotely-reset streams are counted.
+            if stream.state.is_remote_reset() {
+                me.counts.dec_num_remote_reset_streams();
+            }
+
             StreamRef {
                 opaque: OpaqueStreamRef::new(self.inner.clone(), stream),
                 send_buffer: self.send_buffer.clone(),
@@ -598,7 +604,7 @@ impl Inner {
         let actions = &mut self.actions;
 
         self.counts.transition(stream, |counts, stream| {
-            actions.recv.recv_reset(frame, stream);
+            actions.recv.recv_reset(frame, stream, counts)?;
             actions.send.recv_err(send_buffer, stream, counts);
             assert!(stream.state.is_closed());
             Ok(())
diff --git a/vendor/h2/src/server.rs b/vendor/h2/src/server.rs
index 6ad010bd..9b6693bb 100644
--- a/vendor/h2/src/server.rs
+++ b/vendor/h2/src/server.rs
@@ -238,6 +238,10 @@ pub struct Builder {
     /// Maximum number of locally reset streams to keep at a time.
     reset_stream_max: usize,
 
+    /// Maximum number of remotely reset streams to allow in the pending
+    /// accept queue.
+    pending_accept_reset_stream_max: usize,
+
     /// Initial `Settings` frame to send as part of the handshake.
     settings: Settings,
 
@@ -557,6 +561,13 @@ where
     pub fn max_concurrent_recv_streams(&self) -> usize {
         self.connection.max_recv_streams()
     }
+
+    // Could disappear at anytime.
+    #[doc(hidden)]
+    #[cfg(feature = "unstable")]
+    pub fn num_wired_streams(&self) -> usize {
+        self.connection.num_wired_streams()
+    }
 }
 
 #[cfg(feature = "stream")]
@@ -616,6 +627,7 @@ impl Builder {
         Builder {
             reset_stream_duration: Duration::from_secs(proto::DEFAULT_RESET_STREAM_SECS),
             reset_stream_max: proto::DEFAULT_RESET_STREAM_MAX,
+            pending_accept_reset_stream_max: proto::DEFAULT_REMOTE_RESET_STREAM_MAX,
             settings: Settings::default(),
             initial_target_connection_window_size: None,
         }
@@ -855,6 +867,49 @@ impl Builder {
         self
     }
 
+    /// Sets the maximum number of pending-accept remotely-reset streams.
+    ///
+    /// Streams that have been received by the peer, but not accepted by the
+    /// user, can also receive a RST_STREAM. This is a legitimate pattern: one
+    /// could send a request and then shortly after, realize it is not needed,
+    /// sending a CANCEL.
+    ///
+    /// However, since those streams are now "closed", they don't count towards
+    /// the max concurrent streams. So, they will sit in the accept queue,
+    /// using memory.
+    ///
+    /// When the number of remotely-reset streams sitting in the pending-accept
+    /// queue reaches this maximum value, a connection error with the code of
+    /// `ENHANCE_YOUR_CALM` will be sent to the peer, and returned by the
+    /// `Future`.
+    ///
+    /// The default value is currently 20, but could change.
+    ///
+    /// # Examples
+    ///
+    ///
+    /// ```
+    /// # use tokio::io::{AsyncRead, AsyncWrite};
+    /// # use h2::server::*;
+    /// #
+    /// # fn doc<T: AsyncRead + AsyncWrite + Unpin>(my_io: T)
+    /// # -> Handshake<T>
+    /// # {
+    /// // `server_fut` is a future representing the completion of the HTTP/2
+    /// // handshake.
+    /// let server_fut = Builder::new()
+    ///     .max_pending_accept_reset_streams(100)
+    ///     .handshake(my_io);
+    /// # server_fut
+    /// # }
+    /// #
+    /// # pub fn main() {}
+    /// ```
+    pub fn max_pending_accept_reset_streams(&mut self, max: usize) -> &mut Self {
+        self.pending_accept_reset_stream_max = max;
+        self
+    }
+
     /// Sets the maximum number of concurrent locally reset streams.
     ///
     /// When a stream is explicitly reset by either calling
@@ -1269,6 +1324,7 @@ where
                     initial_max_send_streams: 0,
                     reset_stream_duration: self.builder.reset_stream_duration,
                     reset_stream_max: self.builder.reset_stream_max,
+                    remote_reset_stream_max: self.builder.pending_accept_reset_stream_max,
                     settings: self.builder.settings.clone(),
                 },
             );
-- 
2.25.1

